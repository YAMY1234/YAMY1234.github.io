<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID | Chase your light, and light up your life!</title><meta name="keywords" content="Rabbit, here we go!"><meta name="author" content="YAMY"><meta name="copyright" content="YAMY"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="National Innovation and Entrepreneurship Training - Cross-Domain Pedestrian Re-identification ProjectResearch Background and SignificanceWhat is Re-ID?Is the use of Computer Vision technology to deter">
<meta property="og:type" content="article">
<meta property="og:title" content="project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID">
<meta property="og:url" content="http://yamy1234.github.io/2022/12/14/crossDomainReidentification/index.html">
<meta property="og:site_name" content="Chase your light, and light up your life!">
<meta property="og:description" content="National Innovation and Entrepreneurship Training - Cross-Domain Pedestrian Re-identification ProjectResearch Background and SignificanceWhat is Re-ID?Is the use of Computer Vision technology to deter">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yamy1234.github.io/img/1.jpg">
<meta property="article:published_time" content="2022-12-14T04:23:37.000Z">
<meta property="article:modified_time" content="2022-12-14T04:58:34.232Z">
<meta property="article:author" content="YAMY">
<meta property="article:tag" content="Rabbit, here we go!">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yamy1234.github.io/img/1.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yamy1234.github.io/2022/12/14/crossDomainReidentification/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-14 12:58:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/head.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">19</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/1.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Chase your light, and light up your life!</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-14T04:23:37.000Z" title="Created 2022-12-14 12:23:37">2022-12-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-12-14T04:58:34.232Z" title="Updated 2022-12-14 12:58:34">2022-12-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="National-Innovation-and-Entrepreneurship-Training-Cross-Domain-Pedestrian-Re-identification-Project"><a href="#National-Innovation-and-Entrepreneurship-Training-Cross-Domain-Pedestrian-Re-identification-Project" class="headerlink" title="National Innovation and Entrepreneurship Training - Cross-Domain Pedestrian Re-identification Project"></a>National Innovation and Entrepreneurship Training - Cross-Domain Pedestrian Re-identification Project</h1><h2 id="Research-Background-and-Significance"><a href="#Research-Background-and-Significance" class="headerlink" title="Research Background and Significance"></a>Research Background and Significance</h2><h3 id="What-is-Re-ID"><a href="#What-is-Re-ID" class="headerlink" title="What is Re-ID?"></a>What is Re-ID?</h3><p>Is the use of Computer Vision technology to determine whether there is a specific pedestrian in the image or video sequence technology.</p>
<p><img src="image-20221214113657889.png" alt="image-20221214113657889"></p>
<p>Its application scenarios include: intelligent security, intelligent business - unmanned supermarket, human-machine interaction, album Clustering, etc</p>
<p><img src="image-20221214113820200.png" alt="image-20221214113820200"></p>
<p>“Baby Home”, the largest unofficial website for searching for children in China, has 710 pages of “search posts” on its forums, with flagged posts showing that 14,185 boys and 6,938 girls are still missing. On the CCTV official search platform, it shows that 315,588 search messages are pending, the main type of which is family search.</p>
<p>If not AI In the face of surveillance video, it takes a lot of energy to find people. In the case of an old man who got lost not long ago, “If it weren’t for AI, we would need to check nearly 300 cameras to find the whereabouts of the old man. Suppose we check 10 hours of video every day, 3,000 hours of video data, and watch it for 150 consecutive days without eating or sleeping. But through the video structure system, this work is shortened to a few minutes, which buys time and labor costs for the search.”</p>
<p>AI There have been many success stories, but Prior Art relies heavily on facial recognition.<br>Due to the wide range of viewing angles and long distances, most ordinary security surveillance cameras cannot obtain images that meet the facial recognition resolution. The factors affecting recognition include lighting, posture, occlusion, etc., among which clarity is a key element of facial recognition accuracy. AI Factors affecting recognition include illumination, posture, occlusion, etc.<br>A technical method that can simultaneously find all target leads at one time through various attributes such as face, human body, clothing, state, and environmental characteristics is needed to speed up the search for efficiency.</p>
<h3 id="Related-work-and-issues"><a href="#Related-work-and-issues" class="headerlink" title="Related work and issues"></a>Related work and issues</h3><p>Existing pedestrian re-identification techniques have made great progress in single-domain pedestrian re-identification (ReID) recently, but there are great difficulties in cross-domain (cross domain, or transfer) problems.</p>
<p><img src="image-20221214114008624.png" alt="image-20221214114008624"></p>
<p>If the trained model is directly used for target domain testing, the performance will be greatly reduced. For example, the current model with an F1-score of up to 95% on Market1501 is directly used for non-homologous tasks, such as DukeMTMC-reid, and Top1 is often less than 40%. This problem is especially serious considering the relatively small dataset and single scenario in the ReID domain.</p>
<p><strong>Therefore, this Research aims to solve this problem by improving the TransReID model, using the encoder in transformer to obtain the relevant features of the image, and using the decoder to perform cross-domain fusion. In order to achieve transfer learning ability.</strong> The final test results show that the accuracy data reaches a high level of existing cross-domain pedestrian re-identification. Although it is not obvious due to the existing state-of-the-art method, the value is relatively close.</p>
<h2 id="The-main-innovations-and-contributions-of-this-article"><a href="#The-main-innovations-and-contributions-of-this-article" class="headerlink" title="The main innovations and contributions of this article"></a>The main innovations and contributions of this article</h2><p><strong>Research content innovation</strong>: Accurately captured the characteristics of the current pedestrian re-identification in the cross-domain field with low effect, a wide corresponding technology app store and large demand potential, turned the traditional single-domain accuracy to a more practical cross-domain situation, and effectively solved the problem of rapid decline in model accuracy.</p>
<p><strong>Dataset innovation</strong>: Most of the existing datasets mostly exist on campus and cannot be well migrated to social scenes. The idealized dataset we hope to obtain should include: more pedestrians and cameras, more complex scenes, and a wider time span. However, the existing datasets lack data collection for such situations. We have produced a new dataset domain belonging to Tongji University Jiading Campus and labeled it with certain personal use value.</p>
<p><strong>Improvement and innovation of advanced methods</strong>: combined with the current popular transformer framework, TransReID, a single-domain SOTA method, is combined with transfer learning combined to innovate cross-domain pedestrian re-identification. And by changing the attention mechanism, the feature fusion of multiple domains is used as the attention target, so as to have better model effect</p>
<h2 id="Research-Process"><a href="#Research-Process" class="headerlink" title="Research Process"></a>Research Process</h2><p><strong>Phase 1</strong></p>
<p>The topic was determined, the model was initially explored, and the first stage of dataset production was completed.</p>
<p><strong>Phase 2</strong></p>
<p>Determine the basic model - Transformer network; compare ResNet, D-MMD, transGan, Transformer horizontally; reproduce and evaluate their corresponding strengths and weaknesses.</p>
<p><strong>Phase 3</strong></p>
<p>Improve the Transformer network structure on the basic model. Complete the third-stage dataset collection process, participate in the Internet + competition and win the gold medal in the final of the Tongji school competition</p>
<p><strong>Phase 4</strong></p>
<p>Further improve the Transformer network structure. Complete the fourth stage dataset collection process; complete the writing of the full paper and the realization of the final result</p>
<p><strong>Follow-up outlook</strong></p>
<p>Enrich the model and explore the subsequent business value of the model</p>
<h2 id="Research-content-and-results"><a href="#Research-content-and-results" class="headerlink" title="Research content and results"></a>Research content and results</h2><h3 id="Improve-Sota-ReID-Build-a-new-TransReId-model"><a href="#Improve-Sota-ReID-Build-a-new-TransReId-model" class="headerlink" title="Improve Sota ReID - Build a new TransReId model"></a>Improve Sota ReID - Build a new TransReId model</h3><p>The Sota ReID model proposed by Alibaba Research Institute and Zhejiang University can perform well on a single domain, but not on a cross-domain basis. Therefore, we improve the TransReId model to focus on the image cross-focus between the two domains and use identity preservation and feature exchange to fuse the information of the two domains.</p>
<p><img src="image-20221214114210182.png" alt="image-20221214114210182"></p>
<h3 id="Feature-extraction"><a href="#Feature-extraction" class="headerlink" title="Feature extraction"></a>Feature extraction</h3><p>For an input image, the model first divides it into blocks of fixed size. For each block, a linear operation is used to map it to the D dimension. It should be noted that instead of simply cutting the image directly, there are overlapping Patches. This is because in the pure transformer model (eg ViT, DeiT), the image is segmented into non-overlapping Patches, thus losing the local adjacent structures around them.</p>
<h3 id="Measurement-method"><a href="#Measurement-method" class="headerlink" title="Measurement method"></a>Measurement method</h3><p>The model uses ID loss combined with triple loss.</p>
<p>ID loss is the loss caused by the classification, the obtained features through a classifier, the classification is correct using cross-heir calculation.</p>
<p>The triplet loss is to directly use the global feature representation obtained by the last layer of transformer to calculate whether the difference between the distance between the positive sample pair and the distance between the negative sample pair is greater than the predetermined scale.</p>
<p>ID losses:</p>
<img src="image-20221214114246913.png" alt="image-20221214114246913" style="zoom:50%;">

<p>Triple loss:</p>
<img src="image-20221214114313956.png" alt="image-20221214114313956" style="zoom:50%;">





<p>Method Improvement - Focus on the image cross-over between the two domains, and use identity preservation and feature exchange to fuse the images of the two domains</p>
<p>Referring to the relevant ideas in TransReId, we focus on the image cross-over between the two domains, use identity preservation, feature exchange to fuse the images of the two domains, and exchange again to measure cross-domain consistency.</p>
<p>In our improved model, the encoder in transformer is used to obtain the relevant features of the image, and the decoder is used for cross-domain fusion. Specifically, the encoder and image preprocessing are the same as in TransReID; the decoder is the image generator. The images of the two domains pay attention to each other, and the idea is consistent with transfer learning is to use the source domain to learn the target domain.</p>
<p>In view of transformer’s excellent performance ability in cross-modal related fields, its cross-domain process will also become its advantage</p>
<p>Schematic diagram of key ideas:</p>
<img src="image-20221214114451055.png" alt="image-20221214114451055" style="zoom: 33%;">

<img src="image-20221214114538315.png" alt="image-20221214114538315" style="zoom:33%;">



<h3 id="Collect-pedestrian-re-identification-dataset-on-Tongji-University-campus"><a href="#Collect-pedestrian-re-identification-dataset-on-Tongji-University-campus" class="headerlink" title="Collect pedestrian re-identification dataset on Tongji University campus"></a>Collect pedestrian re-identification dataset on Tongji University campus</h3><p>Since there are relatively few existing datasets dealing with cross-domain problems, we plan to create a cross-domain pedestrian enrichment dataset based on the Tongji University domain at Tongji University:</p>
<p>• We shot the pedestrian re-identification dataset at multiple points in Tongji University, and the shooting locations in spring included: Tongji University Boys Apartment (No. 7 Dormitory Building), Tongji University Jiading Street (1 and 2 gates of the large cafeteria), Tongji University Library (lobby on the first floor, library entrance and exit), Tongji University Teaching Building (corridor on the first floor of Building A, main entrance and exit of Building A).</p>
<p>• We shot the pedestrian re-identification dataset in four seasonal time periods (April, June, September, December), summer, autumn, and winter respectively. The total shooting time in each season is 40 hours (10 hours per location), totaling 160 hours of video data (totaling 158 GB of video). After manual labeling + Machine Learning Labeling processing, we successfully edited tens of thousands of samples of labeled data.</p>
<p>Display of partial sampling points: Site sampling record point 3 – Library of Tongji University：</p>
<p><img src="image-20221214115127834.png" alt="image-20221214115127834"></p>
<h3 id="Make-a-pedestrian-re-identification-dataset-on-Tongji-University-campus"><a href="#Make-a-pedestrian-re-identification-dataset-on-Tongji-University-campus" class="headerlink" title="Make a pedestrian re-identification dataset on Tongji University campus"></a>Make a pedestrian re-identification dataset on Tongji University campus</h3><p>Use the professional pedestrian re-identification and labeling software - DarkLabel1.3_part1 to label the dataset:</p>
<p><img src="image-20221214115223202.png" alt="image-20221214115223202"></p>
<p><img src="image-20221214115235412.png" alt="image-20221214115235412"></p>
<p>A total of more than 160h of recording time was successfully collected and captured data sets of thousands of students in Tongji University-Jiading campus area.</p>
<p><img src="image-20221214115243555.png" alt="image-20221214115243555"></p>
<p>Dataset introduction:</p>
<ol>
<li>Processed data: The processed data set information is shown in the figure above. Each picture is the outline of the pedestrian successfully intercepted, and each picture is composed of person_id, location_id, image_id triples.</li>
</ol>
<img src="image-20221214115735493.png" alt="image-20221214115735493" style="zoom:50%;">

<p>2.Original data source: The original data source is the original video stream data, the user class according to the original video stream to capture more pedestrian movements, modality and other information to process.</p>
<p>Considering information security and privacy, only <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1_rJr54WOA8pubg5PoSWRqKxRE3_RXxWr/view?usp=sharing">Partial Dataset Sample</a> is set to Shared here for viewing dataset quality and information.</p>
<h2 id="Experimental-results"><a href="#Experimental-results" class="headerlink" title="Experimental results"></a>Experimental results</h2><p>First, we use the two most common datasets Market-1501 and Duke’s Pedestrian Enrichment Domain datasets to observe the results of cross-domain pedestrian re-identification on the image relational domain, respectively, using Rank-1, Rank-5, Rank-10, and MAP</p>
<h3 id="Indicator-introduction"><a href="#Indicator-introduction" class="headerlink" title="Indicator introduction"></a>Indicator introduction</h3><h4 id="rank-n"><a href="#rank-n" class="headerlink" title="rank-n"></a>rank-n</h4><p>The probability that the top n graphs in the search results (with the highest Confidence Level) have the correct result.</p>
<p>For example: lable is m1, search in 100 samples.</p>
<p>If the recognition result is m1, m2, m3, m4, m5…, then the correct rate of rank-1 is 100%; the correct rate of rank-2 is also 100%; the correct rate of rank-5 is also 100%;</p>
<p>If the recognition result is m2, m1, m3, m4, m5…, then the correct rate of rank-1 is 0%, the correct rate of rank-2 is 100%, and the correct rate of rank-5 is also 100%.</p>
<p>If the recognition result is m2, m3, m4, m5, m1…, then the correct rate of rank-1 is 0%, the correct rate of rank-2 is 0%, and the correct rate of rank-5 is 100%.</p>
<p>When there are many sets of faces to be recognized, the average value is taken.</p>
<h4 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h4><p>PR area under the curve (PR curve: precision and recall for all samples plotted in the graph)</p>
<p>For example: query-id &#x3D; 1, query-cam &#x3D; 1, gallery has a total of 5 pictures, calculate recall and precision according to the following figure, take recall as abscissa, precision as ordinate, draw PR Curve, the area below the curve is AP, when more than one person needs to be retrieved, take the average mAP of all people at this time.</p>
<p>There are many ways to calculate the area under the curve, such as ap &#x3D; ap + (recall - old_recall) * ((old_precision + precision)&#x2F;2);</p>
<p>AP measures how good the learned model is on a single category, mAP measures how good the learned model is on all categories</p>
<h3 id="Traditional-experimental-results"><a href="#Traditional-experimental-results" class="headerlink" title="Traditional experimental results"></a>Traditional experimental results</h3><p>First, we use the two most common datasets Market-1501 and Duke’s pedestrian enrichment datasets to observe the research results of cross-domain pedestrian re-identification on the image relational domain respectively:</p>
<p><img src="image-20221214114649438.png" alt="image-20221214114649438"></p>
<p>Comparison of experimental results:</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>M &gt;D</th>
<th>D &gt; M</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>mAP</td>
<td>R1</td>
<td>R5</td>
<td>R10</td>
<td>mAP</td>
<td>R1</td>
<td>R5</td>
<td>R10</td>
<td></td>
</tr>
<tr>
<td>UDAt</td>
<td>54.4·</td>
<td>72.7</td>
<td>82.1</td>
<td>85.6</td>
<td>56.5</td>
<td>78.4</td>
<td>86.5</td>
<td>89.5</td>
</tr>
<tr>
<td>UDAt Ten GAN</td>
<td>60.4</td>
<td>76.3</td>
<td>85.8</td>
<td>84.4</td>
<td>70.5</td>
<td>85.8</td>
<td>93.2</td>
<td>95.1</td>
</tr>
<tr>
<td>UDAt + CAMS+ IMSLoss</td>
<td>60.2</td>
<td>76.9</td>
<td>84</td>
<td>86.7</td>
<td>69.3</td>
<td>85.4</td>
<td>92.8</td>
<td>94.8</td>
</tr>
<tr>
<td>UDAt十GAN + IMSLoss</td>
<td>60.2</td>
<td>75.9</td>
<td>85.9</td>
<td>88.8</td>
<td>72.4</td>
<td>86.9</td>
<td>92.9</td>
<td>95.1</td>
</tr>
<tr>
<td>DCML (KNN )</td>
<td>63.3</td>
<td>79.1</td>
<td>87.2</td>
<td>89.4</td>
<td>73.6</td>
<td>87.9</td>
<td>95.0</td>
<td>96.7</td>
</tr>
<tr>
<td>DCML (Prototype )</td>
<td>63.5</td>
<td>79.3</td>
<td>86.7</td>
<td>89.5</td>
<td>73.4</td>
<td>88.2</td>
<td>94.9</td>
<td>96.4</td>
</tr>
<tr>
<td>Ours</td>
<td>63.8</td>
<td>78.9</td>
<td>87.8</td>
<td>90.4</td>
<td>68.7</td>
<td>84.1</td>
<td>92.2</td>
<td>94.7</td>
</tr>
</tbody></table>
<p>The accuracy rate of the data reaches the current high level of cross-domain pedestrian re-identification. Although it is not obvious due to the existing state-of-the-art method, the value is relatively close.</p>
<p>Secondly, we carry out additional tests on the cross-domain pedestrian enrichment dataset of Tongji University. The experimental results show that the dataset under the Tongji University domain has similar statistical results to other datasets, thus proving the usability of the dataset.</p>
<p><img src="image-20221214114736855.png" alt="image-20221214114736855"></p>
<p><img src="image-20221214114742045.png" alt="image-20221214114742045"></p>
<p><img src="image-20221214114748433.png" alt="image-20221214114748433"></p>
<h2 id="Project-Results"><a href="#Project-Results" class="headerlink" title="Project Results"></a>Project Results</h2><ol>
<li>Participated in the 7th China International “Internet +” College Students Innovation and Entrepreneurship Competition and won the gold medal in the school finals</li>
</ol>
<p><img src="image-20221214123037143.png" alt="image-20221214123037143"></p>
<ol start="2">
<li>Participated in the 7th “Excellence Cup” and the 13th “Challenge Cup” Chinese College Students Entrepreneurship Plan Competition of Tongji University</li>
</ol>
<p><img src="image-20221214123048460.png" alt="image-20221214123048460"></p>
<ol start="3">
<li>As an excellent project, publish the 2021-2022 Innovation and Entrepreneurship Project Exhibition Board</li>
</ol>
<p><img src="image-20221214123102919.png" alt="image-20221214123102919"></p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>[1] He, S., Luo, H., Wang, P., Wang, F., Li, H., &amp; Jiang, W. (2021). Transreid: Transformer-based object re-identification. arXiv preprint arXiv:2102.04378.</p>
<p>[2] Xu, T., Chen, W., Wang, P., Wang, F., Li, H., &amp; Jin, R. (2021). Cdtrans: Cross-domain transformer for unsupervised domain adaptation. arXiv preprint arXiv:2109.06165.</p>
<p>[3] Verma, A., Subramanyam, A. V., Wang, Z., Satoh, S. I., &amp; Shah, R. R. (2021). Unsupervised Domain Adaptation for Person Re-identification via Individual-preserving and Environmental-switching Cyclic Generation. IEEE Transactions on Multimedia.</p>
<p>[4] Zou, Y., Yang, X., Yu, Z., Kumar, B. V., &amp; Kautz, J. (2020). Joint disentangling and adaptation for cross-domain person re-identification. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16 (pp. 87-104). Springer International Publishing.</p>
<p>[5] Wu, K., Peng, H., Chen, M., Fu, J., &amp; Chao, H. (2021). Rethinking and improving relative position encoding for vision transformer. In Proceedings of the IEEE&#x2F;CVF International Conference on Computer Vision (pp. 10033-10041).</p>
<p>[6] Yutian Lin, Liang Zheng , Zhedong Zheng, Yu Wu, Zhilan Hu, Chenggang Yan, Yi Yang:Improving person re-identification by attribute and identity learning. Pattern Recognit. 95: 151-161 (2019) </p>
<p>[7] Guangyi Chen, Yuhao Lu, Jiwen Lu, Jie Zhou:Deep Credible Metric Learning for Unsupervised Domain Adaptation Person Re-identification. ECCV (8) 2020: 643-659 </p>
<p>[8] Jianing Li, Shiliang Zhang:Joint Visual and Temporal Consistency for Unsupervised Domain Adaptive Person Re-identification. ECCV (24) 2020: 483-499 </p>
<p>[9] Djebril Mekhazni, Amran Bhuiyan, George S. Eskander Ekladious, Eric Granger:Unsupervised Domain Adaptation in the Dissimilarity Space for Person Re-identification. ECCV (27) 2020: 159-174</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">YAMY</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yamy1234.github.io/2022/12/14/crossDomainReidentification/">http://yamy1234.github.io/2022/12/14/crossDomainReidentification/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/12/13/about_myself/"><img class="prev-cover" src="/img/4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">A Page about Myself</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/13/project-collections-L2TP_VPN_Experiment/"><img class="next-cover" src="/img/4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">project collections: L2TP VPN Experiment</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/head.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">YAMY</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">19</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#National-Innovation-and-Entrepreneurship-Training-Cross-Domain-Pedestrian-Re-identification-Project"><span class="toc-number">1.</span> <span class="toc-text">National Innovation and Entrepreneurship Training - Cross-Domain Pedestrian Re-identification Project</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Research-Background-and-Significance"><span class="toc-number">1.1.</span> <span class="toc-text">Research Background and Significance</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#What-is-Re-ID"><span class="toc-number">1.1.1.</span> <span class="toc-text">What is Re-ID?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Related-work-and-issues"><span class="toc-number">1.1.2.</span> <span class="toc-text">Related work and issues</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-main-innovations-and-contributions-of-this-article"><span class="toc-number">1.2.</span> <span class="toc-text">The main innovations and contributions of this article</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Research-Process"><span class="toc-number">1.3.</span> <span class="toc-text">Research Process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Research-content-and-results"><span class="toc-number">1.4.</span> <span class="toc-text">Research content and results</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Improve-Sota-ReID-Build-a-new-TransReId-model"><span class="toc-number">1.4.1.</span> <span class="toc-text">Improve Sota ReID - Build a new TransReId model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-extraction"><span class="toc-number">1.4.2.</span> <span class="toc-text">Feature extraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Measurement-method"><span class="toc-number">1.4.3.</span> <span class="toc-text">Measurement method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Collect-pedestrian-re-identification-dataset-on-Tongji-University-campus"><span class="toc-number">1.4.4.</span> <span class="toc-text">Collect pedestrian re-identification dataset on Tongji University campus</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Make-a-pedestrian-re-identification-dataset-on-Tongji-University-campus"><span class="toc-number">1.4.5.</span> <span class="toc-text">Make a pedestrian re-identification dataset on Tongji University campus</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Experimental-results"><span class="toc-number">1.5.</span> <span class="toc-text">Experimental results</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Indicator-introduction"><span class="toc-number">1.5.1.</span> <span class="toc-text">Indicator introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#rank-n"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">rank-n</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mAP"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">mAP</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Traditional-experimental-results"><span class="toc-number">1.5.2.</span> <span class="toc-text">Traditional experimental results</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Project-Results"><span class="toc-number">1.6.</span> <span class="toc-text">Project Results</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">2.</span> <span class="toc-text">References</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/12/13/about_myself/" title="A Page about Myself"><img src="/img/4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A Page about Myself"/></a><div class="content"><a class="title" href="/2023/12/13/about_myself/" title="A Page about Myself">A Page about Myself</a><time datetime="2023-12-13T11:13:37.000Z" title="Created 2023-12-13 19:13:37">2023-12-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/14/crossDomainReidentification/" title="project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID"><img src="/img/1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID"/></a><div class="content"><a class="title" href="/2022/12/14/crossDomainReidentification/" title="project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID">project collections: National Innovation and Entrepreneurship Training - Cross-Domain ReID</a><time datetime="2022-12-14T04:23:37.000Z" title="Created 2022-12-14 12:23:37">2022-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/13/project-collections-L2TP_VPN_Experiment/" title="project collections: L2TP VPN Experiment"><img src="/img/4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="project collections: L2TP VPN Experiment"/></a><div class="content"><a class="title" href="/2022/12/13/project-collections-L2TP_VPN_Experiment/" title="project collections: L2TP VPN Experiment">project collections: L2TP VPN Experiment</a><time datetime="2022-12-13T04:23:37.000Z" title="Created 2022-12-13 12:23:37">2022-12-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/13/project-collections-RSA_Encript_System/" title="project collections: RSA Encrypt System"><img src="/img/4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="project collections: RSA Encrypt System"/></a><div class="content"><a class="title" href="/2022/12/13/project-collections-RSA_Encript_System/" title="project collections: RSA Encrypt System">project collections: RSA Encrypt System</a><time datetime="2022-12-13T04:16:37.000Z" title="Created 2022-12-13 12:16:37">2022-12-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/13/project-collections-LinuxPersonalFirewall/" title="project collections: Linux Personal Firewall"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="project collections: Linux Personal Firewall"/></a><div class="content"><a class="title" href="/2022/12/13/project-collections-LinuxPersonalFirewall/" title="project collections: Linux Personal Firewall">project collections: Linux Personal Firewall</a><time datetime="2022-12-13T04:13:37.000Z" title="Created 2022-12-13 12:13:37">2022-12-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By YAMY</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>